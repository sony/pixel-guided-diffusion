# Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models 
[![arXiv](https://img.shields.io/badge/arXiv-2212.02024-red)](https://arxiv.org/abs/2212.02024)  
Official implementation of the paper [Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models](https://arxiv.org/abs/2212.02024) accepted by **AI for Content Creation workshop at CVPR2023**

This code is implemented in [nnabla](https://nnabla.org/) and [pytorch](https://pytorch.org/).  
Please see each repository for setup and demonstration, respectively.

**NOTE**: If you want to clone a submodule as well, clone it with **--recursive**.

## Overview
Our approach with pixel-wise gradient-based guidance with diffusion models enables fine-grained image editing. An existing GAN-based method fails to recontruct detailed features. In contrust, our diffusion-based method enables pixel-wise editing while preserving detailed features.
<p align="center">
  <img src="images/Animation.gif">
</p> 


## References
```
@article{matsunaga2022fine,
  title={Fine-grained Image Editing by Pixel-wise Guidance Using Diffusion Models},
  author={Matsunaga, Naoki and Ishii, Masato and Hayakawa, Akio and Suzuki, Kenji and Narihira, Takuya},
  journal={AI for Content Creation workshop at CVPR2023},
  year={2022}
}
```



